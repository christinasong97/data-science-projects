{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9533dae1",
   "metadata": {
    "id": "9533dae1"
   },
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "EAGLUTXpAuWj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAGLUTXpAuWj",
    "outputId": "2c587971-835e-4de1-91b5-d404531661de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NSLaD_kBA2Y2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NSLaD_kBA2Y2",
    "outputId": "70c83234-12aa-400d-c865-32bfa0bb8b0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/drive/My Drive/merged_df.csv', index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecb8e48",
   "metadata": {
    "id": "0ecb8e48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>user_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_reviews</th>\n",
       "      <th>review_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is nice little Chinese bakery in the hear...</td>\n",
       "      <td>nice little chinese bakery heart philadelphia ...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is the bakery I usually go to in Chinatow...</td>\n",
       "      <td>bakery usually go chinatown decent variety bun...</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A delightful find in Chinatown! Very clean, an...</td>\n",
       "      <td>delightful find chinatown clean kind service e...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I ordered a graduation cake for my niece and i...</td>\n",
       "      <td>ordered graduation cake niece came absolutely ...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HK-STYLE MILK TEA:  FOUR STARS\\n\\nNot quite su...</td>\n",
       "      <td>hkstyle milk tea four star quite sure two sain...</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                name          city state  avg_stars  \\\n",
       "0  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  Philadelphia    PA        4.0   \n",
       "1  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  Philadelphia    PA        4.0   \n",
       "2  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  Philadelphia    PA        4.0   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  Philadelphia    PA        4.0   \n",
       "4  MTSW4McQd7CbVtyjqoe9mw  St Honore Pastries  Philadelphia    PA        4.0   \n",
       "\n",
       "   user_stars                                               text  \\\n",
       "0         4.0  This is nice little Chinese bakery in the hear...   \n",
       "1         4.0  This is the bakery I usually go to in Chinatow...   \n",
       "2         5.0  A delightful find in Chinatown! Very clean, an...   \n",
       "3         5.0  I ordered a graduation cake for my niece and i...   \n",
       "4         4.0  HK-STYLE MILK TEA:  FOUR STARS\\n\\nNot quite su...   \n",
       "\n",
       "                                   processed_reviews  review_words  \n",
       "0  nice little chinese bakery heart philadelphia ...          40.0  \n",
       "1  bakery usually go chinatown decent variety bun...          58.0  \n",
       "2  delightful find chinatown clean kind service e...          22.0  \n",
       "3  ordered graduation cake niece came absolutely ...          16.0  \n",
       "4  hkstyle milk tea four star quite sure two sain...         103.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_df.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07dd72f",
   "metadata": {
    "id": "c07dd72f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2812484, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c39e922",
   "metadata": {
    "id": "3c39e922",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id           1\n",
       "name                  1\n",
       "city                  2\n",
       "state                 2\n",
       "avg_stars             2\n",
       "user_stars            2\n",
       "text                  2\n",
       "processed_reviews    20\n",
       "review_words          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d00b526",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d00b526",
    "outputId": "a660bd50-90c4-4c1c-972e-98a795abb463"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id          0\n",
       "name                 0\n",
       "city                 0\n",
       "state                0\n",
       "avg_stars            0\n",
       "user_stars           0\n",
       "text                 0\n",
       "processed_reviews    0\n",
       "review_words         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b531b9b",
   "metadata": {
    "id": "6b531b9b"
   },
   "outputs": [],
   "source": [
    "top_cities = ['Philadelphia', 'New Orleans', 'Nashville', 'Tampa', 'Tucson', 'Indianapolis', 'Saint Louis',\n",
    "             'Reno', 'Santa Barbara', 'Saint Petersburg', 'Boise', 'Clearwater', 'Metairie',\n",
    "             'Sparks', 'Franklin', 'Wilmington', 'Meridian', 'Saint Louis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d153b7e9",
   "metadata": {
    "id": "d153b7e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                city  review_count\n",
      "4           Meridian         23683\n",
      "16        Wilmington         26947\n",
      "2           Franklin         34214\n",
      "13            Sparks         37977\n",
      "5           Metairie         38028\n",
      "1         Clearwater         49913\n",
      "0              Boise         63634\n",
      "11  Saint Petersburg         76578\n",
      "12     Santa Barbara        147611\n",
      "9               Reno        176096\n",
      "10       Saint Louis        187539\n",
      "3       Indianapolis        213377\n",
      "15            Tucson        219305\n",
      "14             Tampa        264899\n",
      "6          Nashville        284559\n",
      "7        New Orleans        420313\n",
      "8       Philadelphia        547791\n"
     ]
    }
   ],
   "source": [
    "review_count_per_city = df.groupby('city')['business_id'].count().reset_index(name='review_count').sort_values(by='review_count', ascending=True)\n",
    "\n",
    "\n",
    "print(review_count_per_city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453b5e21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "453b5e21",
    "outputId": "6794429a-7c9d-4a5e-bacf-784075d603b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philadelphia:  (547791, 9)\n",
      "New Orleans:  (420313, 9)\n",
      "Nashville:  (284559, 9)\n",
      "Florida:  (391390, 9)\n",
      "Tucson:  (219305, 9)\n",
      "Indianapolis:  (213377, 9)\n",
      "Washoe County:  (214073, 9)\n",
      "Ada County:  (87317, 9)\n",
      "Metairie:  (38028, 9)\n",
      "Franklin:  (34214, 9)\n",
      "Wilmington:  (26947, 9)\n",
      "Santa Barbara:  (147611, 9)\n",
      "Saint Louis:  (187539, 9)\n"
     ]
    }
   ],
   "source": [
    "## Creating 13 different datsets for each county\n",
    "\n",
    "# Philadelphia\n",
    "padf = df[df['city'] == 'Philadelphia']\n",
    "print('Philadelphia: ',padf.shape)\n",
    "\n",
    "# New Orleans\n",
    "nodf = df[df['city'] == 'New Orleans']\n",
    "print('New Orleans: ', nodf.shape)\n",
    "\n",
    "# Nashville\n",
    "nadf = df[df['city'] == 'Nashville']\n",
    "print('Nashville: ', nadf.shape)\n",
    "\n",
    "# Saint Petersburg, Tampa, and Clearwater are neighboring areas in Pineallas County, FL\n",
    "florida_cities = ['Saint Petersburg', 'Tampa', 'Clearwater']\n",
    "fldf = df[df['city'].isin(florida_cities)]\n",
    "print('Florida: ', fldf.shape)\n",
    "\n",
    "# Tucson\n",
    "tudf = df[df['city'] == 'Tucson']\n",
    "print('Tucson: ', tudf.shape)\n",
    "\n",
    "# Indianapolis\n",
    "indf = df[df['city'] == 'Indianapolis']\n",
    "print('Indianapolis: ', indf.shape)\n",
    "\n",
    "# Sparks and Reno are neighboring areas in Washoe County, NV\n",
    "nv_cities = ['Reno', 'Sparks']\n",
    "nvdf = df[df['city'].isin(nv_cities)]\n",
    "print('Washoe County: ', nvdf.shape)\n",
    "\n",
    "# Meridian and Boise are within Ada County, ID\n",
    "ada = ['Meridian', 'Boise']\n",
    "adadf = df[df['city'].isin(ada)]\n",
    "print('Ada County: ', adadf.shape)\n",
    "\n",
    "# Metairie\n",
    "metdf = df[df['city'] == 'Metairie']\n",
    "print('Metairie: ', metdf.shape)\n",
    "\n",
    "# Franklin\n",
    "fadf = df[df['city'] == 'Franklin']\n",
    "print('Franklin: ', fadf.shape)\n",
    "\n",
    "# Wilmington\n",
    "wdf = df[df['city'] == 'Wilmington']\n",
    "print('Wilmington: ', wdf.shape)\n",
    "\n",
    "# Santa Barbara\n",
    "sbdf = df[df['city'] == 'Santa Barbara']\n",
    "print('Santa Barbara: ', sbdf.shape)\n",
    "\n",
    "# Saint Louis\n",
    "sldf = df[df['city'] == 'Saint Louis']\n",
    "print('Saint Louis: ', sldf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77019372",
   "metadata": {
    "id": "77019372"
   },
   "source": [
    "We will run TF-IDF in this order since kernel keeps dying with larger corpus (like for Philadelphia):\n",
    "1. Wilmington - 26947\n",
    "2. Franklin - 34214\n",
    "3. Metairie - 38028\n",
    "4. Ada County - 87317\n",
    "5. Santa Barbara - 147611\n",
    "6. Saint Louis - 187539\n",
    "7. Indianapolis - 213377\n",
    "8. Washoe County - 214073\n",
    "9. Tucson - 219305\n",
    "10. Nashville - 284559\n",
    "11. Florida - 391390\n",
    "12. New Orleans - 420313\n",
    "13. Philadelphia - 547791\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58c196",
   "metadata": {
    "id": "ba58c196"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1b4a3b",
   "metadata": {
    "id": "3e1b4a3b"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce50ad",
   "metadata": {
    "id": "52ce50ad"
   },
   "source": [
    "## First 30 reviews for PA\n",
    "For proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a63eaa2",
   "metadata": {
    "id": "3a63eaa2"
   },
   "outputs": [],
   "source": [
    "# test TF-IDF on first 30 rows of reviews\n",
    "\n",
    "corpus = padf['processed_reviews'].tolist()\n",
    "corpus_reduced = corpus[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c596eb01",
   "metadata": {
    "id": "c596eb01"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus_reduced)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_padf_reduced = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_padf_reduced['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55719f0",
   "metadata": {
    "id": "d55719f0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correlation\n",
      "also           0.435733\n",
      "flavor         0.405554\n",
      "strawberry     0.397731\n",
      "world          0.344618\n",
      "gem            0.344618\n",
      "nice           0.343942\n",
      "absolutely     0.343621\n",
      "come           0.323810\n",
      "go             0.320112\n",
      "place          0.319157\n",
      "ton            0.312283\n",
      "ive            0.311602\n",
      "made           0.306853\n",
      "delicious      0.285178\n",
      "ordered        0.275230\n",
      "cake           0.259879\n",
      "without        0.256012\n",
      "perfect        0.244142\n",
      "upon           0.240206\n",
      "stumbled       0.240206\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "correlations = {}\n",
    "for word in tfidf_padf_reduced.columns[:-1]:  # Exclude the 'rating' column\n",
    "    correlations[word] = pearsonr(tfidf_padf_reduced[word], tfidf_padf_reduced['user_rating'])[0]\n",
    "\n",
    "# Convert to DataFrame for nicer display and sort by correlation\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))  # Show top 20 words most positively correlated with ratings\n",
    "\n",
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_padf_reduced[top_20_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b35cf",
   "metadata": {
    "id": "4b0b35cf"
   },
   "source": [
    "### Wilmington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81b19cba",
   "metadata": {
    "id": "81b19cba"
   },
   "outputs": [],
   "source": [
    "# Start with Wilmington since it has the smallest review count\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = wdf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_wdf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_wdf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09803cbf",
   "metadata": {
    "id": "09803cbf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             correlation\n",
      "hill            0.025091\n",
      "tea             0.020431\n",
      "provided        0.020103\n",
      "ulysses         0.019569\n",
      "experienced     0.019032\n",
      "burrito         0.018666\n",
      "iron            0.018401\n",
      "decision        0.017937\n",
      "el              0.017451\n",
      "suite           0.017389\n",
      "lady            0.017267\n",
      "community       0.016936\n",
      "dave            0.016691\n",
      "soggy           0.015975\n",
      "gelato          0.015930\n",
      "charged         0.015800\n",
      "valet           0.015743\n",
      "worked          0.015732\n",
      "bellefonte      0.015685\n",
      "sherry          0.015676\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_wdf.columns[:-1]:  # Exclude the 'rating' column\n",
    "    correlations[word] = pearsonr(tfidf_wdf[word], tfidf_wdf['user_rating'])[0]\n",
    "\n",
    "# Convert to DataFrame for nicer display and sort by correlation\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))  # Show top 20 words most positively correlated with ratings\n",
    "\n",
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_wdf[top_20_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "OHf5nnHgUZPj",
   "metadata": {
    "id": "OHf5nnHgUZPj"
   },
   "outputs": [],
   "source": [
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "wm_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "wdf['Wilmington_SVD'] = wm_words_svd[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553068d",
   "metadata": {
    "id": "2553068d"
   },
   "source": [
    "### Franklin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8768333d",
   "metadata": {
    "id": "8768333d"
   },
   "outputs": [],
   "source": [
    "corpus = fadf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_fadf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_fadf['user_rating'] = df['user_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1ef0f2",
   "metadata": {
    "id": "dd1ef0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correlation\n",
      "chuys          0.030843\n",
      "mellow         0.021062\n",
      "cheesecake     0.021005\n",
      "shake          0.020739\n",
      "buca           0.019631\n",
      "level          0.019162\n",
      "special        0.018129\n",
      "duck           0.018128\n",
      "bagel          0.018118\n",
      "cake           0.018072\n",
      "pony           0.017773\n",
      "salad          0.017622\n",
      "upstairs       0.017277\n",
      "breakfast      0.017185\n",
      "long           0.017051\n",
      "delish         0.016726\n",
      "dressing       0.016525\n",
      "fried          0.016220\n",
      "southern       0.016112\n",
      "waiter         0.016008\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_fadf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_fadf[word], tfidf_fadf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8f465b1",
   "metadata": {
    "id": "e8f465b1"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_fadf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "fa_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "fadf['Franklin_SVD'] = fa_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48002312",
   "metadata": {
    "id": "48002312"
   },
   "source": [
    "### Metairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfaec144",
   "metadata": {
    "id": "dfaec144"
   },
   "outputs": [],
   "source": [
    "corpus = metdf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_metdf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_metdf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "526f5ca4",
   "metadata": {
    "id": "526f5ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           correlation\n",
      "pizza         0.043201\n",
      "coffee        0.023135\n",
      "italian       0.022580\n",
      "crust         0.022559\n",
      "frozen        0.021577\n",
      "beer          0.020788\n",
      "old           0.020669\n",
      "wine          0.020364\n",
      "daiquiri      0.019048\n",
      "beignet       0.018457\n",
      "great         0.018432\n",
      "martin        0.018375\n",
      "lasagna       0.017182\n",
      "age           0.016621\n",
      "ravioli       0.016553\n",
      "pepperoni     0.016410\n",
      "york          0.015993\n",
      "bar           0.015766\n",
      "twain         0.015300\n",
      "queso         0.015284\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_metdf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_metdf[word], tfidf_metdf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77caf8bb",
   "metadata": {
    "id": "77caf8bb"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_metdf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "met_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "metdf['Metairie_SVD'] = met_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cccc54",
   "metadata": {
    "id": "58cccc54"
   },
   "source": [
    "### Ada County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60b35fe8",
   "metadata": {
    "id": "60b35fe8"
   },
   "outputs": [],
   "source": [
    "corpus = adadf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus) \n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_adadf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_adadf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5638a02b",
   "metadata": {
    "id": "5638a02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           correlation\n",
      "thai          0.023555\n",
      "kabob         0.017276\n",
      "pad           0.015682\n",
      "chang         0.014999\n",
      "goldys        0.014293\n",
      "brazilian     0.014226\n",
      "chandler      0.014131\n",
      "gernika       0.014111\n",
      "guru          0.013718\n",
      "grinder       0.013500\n",
      "beer          0.013473\n",
      "pf            0.013458\n",
      "janjou        0.012768\n",
      "tucanos       0.012326\n",
      "ew            0.012317\n",
      "pineapple     0.012297\n",
      "wrap          0.012066\n",
      "croquetas     0.012047\n",
      "chinese       0.012015\n",
      "pho           0.011845\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_adadf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_adadf[word], tfidf_adadf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "866cc200",
   "metadata": {
    "id": "866cc200"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_adadf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "ada_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "adadf['AdaCounty_SVD'] = ada_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3aebc",
   "metadata": {
    "id": "e7d3aebc"
   },
   "source": [
    "### Santa Barbara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ada4d1b",
   "metadata": {
    "id": "3ada4d1b"
   },
   "outputs": [],
   "source": [
    "corpus = sbdf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_sbdf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_sbdf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f85d31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55f85d31",
    "outputId": "2e572d53-515b-4d5a-fe65-0464358fa3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         correlation\n",
      "wine        0.020956\n",
      "paella      0.017478\n",
      "tasting     0.015685\n",
      "tapa        0.014866\n",
      "korean      0.014770\n",
      "pulpo       0.014735\n",
      "loquita     0.014169\n",
      "mezcal      0.013140\n",
      "bravas      0.012518\n",
      "patatas     0.012475\n",
      "pho         0.012171\n",
      "sevtap      0.012104\n",
      "brewery     0.011881\n",
      "ramen       0.011574\n",
      "cask        0.011198\n",
      "beer        0.010945\n",
      "room        0.010659\n",
      "bottle      0.010572\n",
      "eos         0.010570\n",
      "winery      0.010415\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_sbdf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_sbdf[word], tfidf_sbdf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75de690",
   "metadata": {
    "id": "a75de690"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_sbdf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "sb_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "sbdf['SantaBarbara_SVD'] = sb_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Vro41PpppbkU",
   "metadata": {
    "id": "Vro41PpppbkU"
   },
   "outputs": [],
   "source": [
    "sbdf.to_csv(\"SantaBarbara_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DD_S6HNRQib0",
   "metadata": {
    "id": "DD_S6HNRQib0"
   },
   "source": [
    "## Saint Louis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad6450f",
   "metadata": {
    "id": "1ad6450f"
   },
   "outputs": [],
   "source": [
    "corpus = sldf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus) \n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_sldf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_sldf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "X-1t-1KEQ02T",
   "metadata": {
    "id": "X-1t-1KEQ02T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           correlation\n",
      "cupcake       0.018718\n",
      "afghan        0.014209\n",
      "kingside      0.013420\n",
      "jillys        0.012088\n",
      "scottish      0.011936\n",
      "irish         0.011877\n",
      "eastern       0.011574\n",
      "retreat       0.011573\n",
      "lorenzos      0.011069\n",
      "pudding       0.010988\n",
      "pw            0.010884\n",
      "farmhouse     0.010841\n",
      "sameem        0.010504\n",
      "lumiere       0.010384\n",
      "lorussos      0.010265\n",
      "bar           0.010104\n",
      "corned        0.010093\n",
      "falafel       0.010014\n",
      "sameems       0.009956\n",
      "katies        0.009856\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_sldf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_sldf[word], tfidf_sldf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993d6490",
   "metadata": {
    "id": "993d6490"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_sldf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "sl_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "sldf['SaintLouis_SVD'] = sl_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05776243",
   "metadata": {
    "id": "05776243"
   },
   "outputs": [],
   "source": [
    "sldf.to_csv(\"SaintLouis_SVD.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1RtbaaRFkW",
   "metadata": {
    "id": "dd1RtbaaRFkW"
   },
   "source": [
    "## Indianapolis\n",
    "\n",
    "Since we keep running out of RAM memory and running into issues with computing power, resulting in a dead kernel, we decided to randomly select a portion of the city's dataset to reduce its size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2v6_BnnL8AI5",
   "metadata": {
    "id": "2v6_BnnL8AI5"
   },
   "outputs": [],
   "source": [
    "reduced_indf = indf.sample(frac=0.8, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Miu9pXlVRIO7",
   "metadata": {
    "id": "Miu9pXlVRIO7"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_indf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_indf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_indf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lPmb7PTKRH-A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPmb7PTKRH-A",
    "outputId": "b3340ce6-0579-4f29-d99f-2501165393c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correlation\n",
      "clever         0.008970\n",
      "sea            0.008118\n",
      "amazed         0.007919\n",
      "powered        0.007524\n",
      "saigon         0.007424\n",
      "flavor         0.007421\n",
      "coma           0.007396\n",
      "linguine       0.007331\n",
      "dinner         0.007309\n",
      "curse          0.007219\n",
      "precaution     0.007182\n",
      "citrus         0.007181\n",
      "silverware     0.007115\n",
      "genuine        0.007111\n",
      "grub           0.007002\n",
      "ripoff         0.006930\n",
      "walking        0.006930\n",
      "later          0.006881\n",
      "finishing      0.006823\n",
      "baba           0.006765\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_indf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_indf[word], tfidf_indf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e885bcf",
   "metadata": {
    "id": "4e885bcf"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_indf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "in_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_indf['Indianapolis_SVD'] = in_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ausvtD6r0mOF",
   "metadata": {
    "id": "ausvtD6r0mOF"
   },
   "outputs": [],
   "source": [
    "reduced_indf.to_csv(\"Indianapolis_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JlV3T-VQRK2k",
   "metadata": {
    "id": "JlV3T-VQRK2k"
   },
   "source": [
    "## Washoe County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0SiyqyIc_MUB",
   "metadata": {
    "id": "0SiyqyIc_MUB"
   },
   "outputs": [],
   "source": [
    "reduced_nvdf = nvdf.sample(frac=0.8, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uzc5gQ65RL1z",
   "metadata": {
    "id": "uzc5gQ65RL1z"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_nvdf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_nvdf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_nvdf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Vj9e1yWZRLiO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vj9e1yWZRLiO",
    "outputId": "e4577742-bfc8-467c-cac9-c71cc5503b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               correlation\n",
      "screen            0.009992\n",
      "saloon            0.008214\n",
      "amazed            0.008095\n",
      "mia               0.007894\n",
      "cleanliness       0.007694\n",
      "inconvenience     0.007436\n",
      "scrambled         0.007418\n",
      "fountain          0.007415\n",
      "discounted        0.007381\n",
      "various           0.007340\n",
      "raf               0.007272\n",
      "servicing         0.007244\n",
      "identify          0.007120\n",
      "777               0.007108\n",
      "available         0.007002\n",
      "mels              0.006917\n",
      "proceeded         0.006914\n",
      "celebrate         0.006875\n",
      "irked             0.006860\n",
      "category          0.006848\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_nvdf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_nvdf[word], tfidf_nvdf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d96656",
   "metadata": {
    "id": "c7d96656"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_nvdf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "nv_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_nvdf['WashoeCounty_SVD'] = nv_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ejEQV5rG0UAj",
   "metadata": {
    "id": "ejEQV5rG0UAj"
   },
   "outputs": [],
   "source": [
    "reduced_nvdf.to_csv(\"WashoeCounty_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ox1mZo02RPSL",
   "metadata": {
    "id": "ox1mZo02RPSL"
   },
   "source": [
    "## Tucson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "-kyljSVwEHe6",
   "metadata": {
    "id": "-kyljSVwEHe6"
   },
   "outputs": [],
   "source": [
    "reduced_tudf = tudf.sample(frac=0.75, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wcdKI-McRQ7u",
   "metadata": {
    "id": "wcdKI-McRQ7u"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_tudf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_tudf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_tudf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "qpQe3vsORQu_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpQe3vsORQu_",
    "outputId": "c5a32c08-fe11-47d4-98c2-165961389aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correlation\n",
      "ruben          0.009323\n",
      "liquor         0.008513\n",
      "dressing       0.007609\n",
      "lucky          0.007470\n",
      "smaller        0.007440\n",
      "occasion       0.007425\n",
      "lately         0.007394\n",
      "525            0.007389\n",
      "meager         0.007321\n",
      "automatic      0.007118\n",
      "convenient     0.007072\n",
      "ie             0.007054\n",
      "rear           0.007043\n",
      "energetic      0.006933\n",
      "polenta        0.006770\n",
      "nonprofit      0.006724\n",
      "upscale        0.006688\n",
      "ruin           0.006628\n",
      "doable         0.006618\n",
      "yummmm         0.006597\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_tudf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_tudf[word], tfidf_tudf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4c6465",
   "metadata": {
    "id": "ed4c6465"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_tudf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "tu_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_tudf['Tucson_SVD'] = tu_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6v4sJWvHFHd7",
   "metadata": {
    "id": "6v4sJWvHFHd7"
   },
   "outputs": [],
   "source": [
    "reduced_tudf.to_csv(\"Tucson_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4yJFgk83RS5G",
   "metadata": {
    "id": "4yJFgk83RS5G"
   },
   "source": [
    "## Nashville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "h6JN7jxKS7Sm",
   "metadata": {
    "id": "h6JN7jxKS7Sm"
   },
   "outputs": [],
   "source": [
    "reduced_nadf = nadf.sample(frac=0.6, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0_ty0AvnRSiG",
   "metadata": {
    "id": "0_ty0AvnRSiG"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_nadf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_nadf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_nadf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "BXatAuLQRVvT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXatAuLQRVvT",
    "outputId": "f7ad241f-0ccb-4cbb-cb18-67070268a989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               correlation\n",
      "nipper            0.008528\n",
      "missed            0.008199\n",
      "chalkboard        0.007748\n",
      "patio             0.007450\n",
      "spacious          0.007438\n",
      "delight           0.007296\n",
      "money             0.007213\n",
      "located           0.007197\n",
      "square            0.007159\n",
      "glad              0.007083\n",
      "german            0.007012\n",
      "tofu              0.006852\n",
      "1130              0.006845\n",
      "chill             0.006664\n",
      "krogers           0.006649\n",
      "hungover          0.006594\n",
      "highest           0.006587\n",
      "hawker            0.006565\n",
      "knowledgeable     0.006521\n",
      "darfons           0.006521\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_nadf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_nadf[word], tfidf_nadf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e183a0",
   "metadata": {
    "id": "35e183a0"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_nadf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "na_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_nadf['Nashville_SVD'] = na_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "op46enrHkR0E",
   "metadata": {
    "id": "op46enrHkR0E"
   },
   "outputs": [],
   "source": [
    "reduced_nadf.to_csv(\"Nashville_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NSzk9AThRXcd",
   "metadata": {
    "id": "NSzk9AThRXcd"
   },
   "source": [
    "## Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ag9Xp1zykJTq",
   "metadata": {
    "id": "ag9Xp1zykJTq"
   },
   "outputs": [],
   "source": [
    "reduced_fldf = fldf.sample(frac=0.45, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "M4d7yStuRY3m",
   "metadata": {
    "id": "M4d7yStuRY3m"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_fldf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_fldf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_fldf['user_rating'] = df['user_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "QR4a3WLSRYtd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QR4a3WLSRYtd",
    "outputId": "888d018c-4ff6-4b83-d1fd-746ed5bbf662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               correlation\n",
      "underwhelming     0.008292\n",
      "pouring           0.008038\n",
      "admit             0.007908\n",
      "onion             0.007778\n",
      "questionable      0.007752\n",
      "pulled            0.007735\n",
      "horrid            0.007276\n",
      "counter           0.007210\n",
      "blanc             0.007189\n",
      "candle            0.007175\n",
      "gimmicky          0.007014\n",
      "saturday          0.006876\n",
      "furry             0.006873\n",
      "opening           0.006735\n",
      "grocery           0.006698\n",
      "cheesesteaks      0.006537\n",
      "kosher            0.006519\n",
      "stomping          0.006454\n",
      "pure              0.006450\n",
      "structure         0.006423\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_fldf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_fldf[word], tfidf_fldf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d70b14",
   "metadata": {
    "id": "92d70b14"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_fldf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "fl_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_fldf['Florida_SVD'] = fl_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "uZA96bpCkTRw",
   "metadata": {
    "id": "uZA96bpCkTRw"
   },
   "outputs": [],
   "source": [
    "reduced_fldf.to_csv(\"Florida_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tFOZnFFPRcTC",
   "metadata": {
    "id": "tFOZnFFPRcTC"
   },
   "source": [
    "## New Orleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "SQlw2nNyngVe",
   "metadata": {
    "id": "SQlw2nNyngVe"
   },
   "outputs": [],
   "source": [
    "reduced_nodf = nodf.sample(frac=0.4, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "PJtD0MfnRaVY",
   "metadata": {
    "id": "PJtD0MfnRaVY"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_nodf['processed_reviews'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_nodf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_nodf['user_rating'] = df['user_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "NpmQC_Y6Rfc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpmQC_Y6Rfc9",
    "outputId": "ff75d0ac-ed5a-4ec7-dbc1-4a0fac2a9e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              correlation\n",
      "ginger           0.009219\n",
      "dude             0.008545\n",
      "sammich          0.007391\n",
      "bachelorette     0.007383\n",
      "fuck             0.007338\n",
      "relation         0.007305\n",
      "kale             0.007295\n",
      "gris             0.007231\n",
      "tighten          0.007189\n",
      "35               0.007147\n",
      "medallion        0.006896\n",
      "giant            0.006804\n",
      "werent           0.006801\n",
      "frustration      0.006637\n",
      "wedding          0.006635\n",
      "tilapia          0.006614\n",
      "appease          0.006593\n",
      "deboned          0.006533\n",
      "breakfast        0.006517\n",
      "foreign          0.006504\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_nodf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_nodf[word], tfidf_nodf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f3d25c",
   "metadata": {
    "id": "c1f3d25c"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_nodf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "no_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_nodf['NewOrleans_SVD'] = no_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "085NMlg2kZbD",
   "metadata": {
    "id": "085NMlg2kZbD"
   },
   "outputs": [],
   "source": [
    "reduced_nodf.to_csv(\"NewOrleans_SVD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sSMldrf_RAvQ",
   "metadata": {
    "id": "sSMldrf_RAvQ"
   },
   "source": [
    "## Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lmgbQ7Whkd5a",
   "metadata": {
    "id": "lmgbQ7Whkd5a"
   },
   "outputs": [],
   "source": [
    "reduced_padf = padf.sample(frac=0.3, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923f1c73",
   "metadata": {
    "id": "923f1c73"
   },
   "outputs": [],
   "source": [
    "corpus = reduced_padf['processed_reviews'].tolist()\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.5)\n",
    "X = vectorizer.fit_transform(corpus)  # 'corpus' is a list of review texts\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "tfidf_padf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the ratings to the DataFrame\n",
    "tfidf_padf['user_rating'] = df['user_stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190faa37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "190faa37",
    "outputId": "bc5967a4-c9d0-4d05-85ad-e3b11fd7c136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correlation\n",
      "picnic         0.008358\n",
      "vegetarian     0.007793\n",
      "touring        0.007754\n",
      "flagged        0.007324\n",
      "scheme         0.007201\n",
      "chewiness      0.007152\n",
      "converted      0.006892\n",
      "pang           0.006807\n",
      "diy            0.006690\n",
      "guard          0.006663\n",
      "bra            0.006501\n",
      "headphone      0.006477\n",
      "pop            0.006454\n",
      "marcie         0.006437\n",
      "pile           0.006428\n",
      "mummer         0.006400\n",
      "liking         0.006384\n",
      "eyeing         0.006381\n",
      "nog            0.006371\n",
      "madness        0.006368\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation for each word with the rating\n",
    "\n",
    "correlations = {}\n",
    "for word in tfidf_padf.columns[:-1]:\n",
    "    correlations[word] = pearsonr(tfidf_padf[word], tfidf_padf['user_rating'])[0]\n",
    "\n",
    "correlations_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['correlation'])\n",
    "correlations_df = correlations_df.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "print(correlations_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052049cd",
   "metadata": {
    "id": "052049cd"
   },
   "outputs": [],
   "source": [
    "top_20_words = correlations_df.head(20).index.tolist()\n",
    "top_words = tfidf_padf[top_20_words]\n",
    "\n",
    "# Initializing Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1)  # Reducing to one feature\n",
    "\n",
    "# Fitting and transforming the data\n",
    "pa_words_svd = svd.fit_transform(top_words)\n",
    "\n",
    "# Adding this feature back to your DataFrame (or use as needed)\n",
    "reduced_padf['Philadelphia_SVD'] = pa_words_svd[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc492ad3",
   "metadata": {
    "id": "bc492ad3"
   },
   "outputs": [],
   "source": [
    "reduced_padf.to_csv(\"Philadelphia_SVD.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
